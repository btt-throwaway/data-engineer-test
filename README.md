![Datahub](logo_dh.png)

## Teste de avaliação para seleção de desenvolvedores Python jr-Web Scraping e Crawlers

### Introdução

Este é um teste prático para avaliar conhecimentos do candidato durante seu processo 
seletivo para a vaga de Engenheiro de Dados. Antes de iniciar, esteja num ambiente tranquilo e confortável, pense no problema e na melhor forma de resolvê-lo.
O nosso objetivo com este desafio é medir o seu conhecimento técnico de engenharia de dados, por isso não vamos estabelecer nenhum tipo de restrição sobre padrões de projeto, organização de código e boas práticas. Realize o teste usando técnicas que você já conhece e tem segurança. Podemos lhe questionar sobre a sua solução durante a entrevista.

### Desafio

Faça um fork do projeto para um repositório publico do seu Github.

Nele contém o arquivo docker-compose.yml que cria no Docker o ambiente necessário para realizar este desafio. Fique a vontade para editar caso necessite.

Os arquivos **offshore_nodes_officers.txt, offshore_nodes_entities.txt e offshore_relationships.txt** deverão ser lidos do disco e imputados em uma base de dados relacional. Crie um pipeline no Airflow para realizar esta tarefa.

O pipeline deve conter uma etapa de tratamento para remover acentuações. Pode realizar outros tratamentos se achar necessário.

##### Não há um prazo pré-estabelecido para a conclusão deste teste, porém o prazo utilizado será considerado para desempate

---

### Resultado

Você deve salvar o(s) script(s) no seu repositório público e enviar o link para o recrutator.

